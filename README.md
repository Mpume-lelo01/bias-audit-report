# 🧪 Bias Audit Report
An AI ethics project focused on identifying and mitigating bias in a machine learning dataset using fairness metrics and responsible AI techniques.

## 📘 Context
Built during CAPACITI's Trustworthy AI and Google’s Responsible AI training. The report audits gender and race bias in a classification model using Python tools and fairness libraries.

## 📊 What It Includes
- Bias detection using fairness metrics
- Visualization of disparities
- Mitigation using reweighting techniques
- Final ethical recommendations

## 📚 Tools Used
- Python (Pandas, NumPy, Matplotlib)
- AI Fairness 360 Toolkit (AIF360)
- Jupyter Notebook
- Google Colab

## 🔍 Key Learnings
- Applied fairness-aware evaluation
- Understood the impact of data imbalance
- Practiced ethical thinking in AI design

## 📬 Contact
Created by Nompumelelo Mkhabela  
[LinkedIn](https://www.linkedin.com/in/nompumelelo-mkhabela-8aa563247) • [GitHub](https://github.com/Mpume-lelo01)
