# ğŸ§ª Bias Audit Report
An AI ethics project focused on identifying and mitigating bias in a machine learning dataset using fairness metrics and responsible AI techniques.

## ğŸ“˜ Context
Built during CAPACITI's Trustworthy AI and Googleâ€™s Responsible AI training. The report audits gender and race bias in a classification model using Python tools and fairness libraries.

## ğŸ“Š What It Includes
- Bias detection using fairness metrics
- Visualization of disparities
- Mitigation using reweighting techniques
- Final ethical recommendations

## ğŸ“š Tools Used
- Python (Pandas, NumPy, Matplotlib)
- AI Fairness 360 Toolkit (AIF360)
- Jupyter Notebook
- Google Colab

## ğŸ” Key Learnings
- Applied fairness-aware evaluation
- Understood the impact of data imbalance
- Practiced ethical thinking in AI design

## ğŸ“¬ Contact
Created by Nompumelelo Mkhabela  
[LinkedIn](https://www.linkedin.com/in/nompumelelo-mkhabela-8aa563247) â€¢ [GitHub](https://github.com/Mpume-lelo01)
